<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="RSE at Sheffield">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>RSE at Sheffield (old posts, page 2) | RSE at Sheffield</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="http://rse.shef.ac.uk/blog/index-2.html">
<link rel="prev" href="." type="text/html">
<link rel="next" href="index-1.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://rse.shef.ac.uk/">

                <span id="blog-title">RSE at Sheffield</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../activities">What we do</a>
                </li>
<li>
<a href="../training">Training</a>
                </li>
<li>
<a href="../blog">Blog</a>
                </li>
<li>
<a href="../community">Community</a>
                </li>
<li>
<a href="../resources">Resources</a>
                </li>
<li>
<a href="../forged">Forged in Sheffield</a>
                </li>
<li>
<a href="../testimonials">Testimonials</a>
                </li>
<li>
<a href="../contact">Contact Us</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    
<div class="postindex">
    <article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="coffee-and-cakes-event/" class="u-url">Coffee and Cakes Event</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/paul-richmond/">Paul Richmond</a>
            </span></p>
            <p class="dateline"><a href="coffee-and-cakes-event/" rel="bookmark"><time class="published dt-published" datetime="2016-09-26T15:42:42+01:00" title="2016-09-26 15:42">2016-09-26 15:42</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>RSE Sheffield is hosting its first coffee and cakes event on <strong>4th October 2016 at 10:00 in the Ada Lovelace</strong> room on 1st floor of the Computer Science Department (Regents Court East). Attendance is free and you don't need to register (or bring coffee and cake with you). Simply call in and take the opportunity to come and have an informal chat about research software.</p>
<p>The event is a community event for anyone not just computer science or members of the RSE team. If you work on software development are an RSE or simply want to talk about some aspect of software or software in teaching then come along.</p>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="intel-R-iceberg/" class="u-url">Accelerated versions of R for Iceberg</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mike-croucher/">Mike Croucher</a>
            </span></p>
            <p class="dateline"><a href="intel-R-iceberg/" rel="bookmark"><time class="published dt-published" datetime="2016-09-12T00:31:35Z" title="2016-09-12 00:31">2016-09-12 00:31</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p><strong>To Long; Didn't Read -- Summary</strong></p>
<p>I've built a version of R on Iceberg that is faster than the standard version for various operations. Documentation is at <a href="http://docs.hpc.shef.ac.uk/en/latest/iceberg/software/apps/r.html">http://docs.hpc.shef.ac.uk/en/latest/iceberg/software/apps/r.html</a>.</p>
<p>If it works more quickly for you, or if you have problems, please let us know by emailing <a href="mailto:rse@sheffield.ac.uk">rse@sheffield.ac.uk</a></p>
<p><strong>Background</strong></p>
<p>I took over building <a href="http://docs.hpc.shef.ac.uk/en/latest/iceberg/software/apps/r.html">R for Iceberg</a>, Sheffield's High Performance Computing System, around a year ago and have been incrementally improving both the install and the documentation with every release. Something that's been bothering me for a while is the lack of optimisation. The standard Iceberg build uses an ancient version of the gcc compiler and (probably) unoptimised versions of <a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">BLAS</a> and <a href="https://en.wikipedia.org/wiki/LAPACK">LAPCK</a>.</p>
<p>BLAS and LAPACK are extremely important libraries -- they provide the code that programs such as R use for linear algebra: Matrix-Matrix multiplication, Cholesky decomposition, principle component analysis and so on. It's important to note that there are lots of implementations of BLAS and LAPACK: <a href="http://math-atlas.sourceforge.net/">ATLAS</a>, <a href="http://www.openblas.net/">OpenBLAS</a> and the <a href="https://software.intel.com/en-us/intel-mkl">Intel MKL</a> are three well-known examples. Written in Fortran, the interfaces of all of these versions are identical, which means you can use them interchangeably, but the speed of the implementation can vary considerably.</p>
<p>The BLAS and LAPACK implementations on Iceberg are undocumented (before my time!) which means that we have no idea what we are dealing with. Perhaps they are optimised, perhaps not. I suspected 'not'.</p>
<p><strong>Building R with the Intel Compiler and MKL</strong></p>
<p>The Intel Compiler Suite often produces the fastest executables of all available compilers for any given piece of Fortran or C/C++ code. Additionally, the Intel MKL is probably the fastest implementation of BLAS and LAPACK available for Intel Hardware. As such, I've had <strong>Build R using Intel Compilers and MKL</strong> on my to-do list for some time.</p>
<p>Following a recent visit to the University of Lancaster, where they've been doing this for a while, I finally bit the bullet and produced some build-scripts. Thanks to Lancaster's Mike Pacey for help with this!  There are two versions (links point to the exact commits that produced the builds used in this article):</p>
<ul>
<li>
<a href="https://github.com/mikecroucher/HPC_Installers/blob/ea4a9f33b705a8cae01841d9c173278fcb486061/apps/R/3.3.1/sheffield/iceberg/intel_15/install_intel_r_sequential.sh">install_intel_r_sequential.sh</a> - Linked to the sequential (i.e. single-core) version of Intel MKL.</li>
<li>
<a href="https://github.com/mikecroucher/HPC_Installers/blob/ea4a9f33b705a8cae01841d9c173278fcb486061/apps/R/3.3.1/sheffield/iceberg/intel_15/install_intel_r_parallel.sh">install_intel_r_parallel.sh</a> - Linked to the parallel version of Intel MKL.</li>
</ul>
<p>The benchmark code is available in the Sheffield HPC examples repo <a href="https://github.com/mikecroucher/HPC_Examples/">https://github.com/mikecroucher/HPC_Examples/</a>. The exact commit that produced these results is <a href="https://github.com/mikecroucher/HPC_Examples/blob/35de11e7c47bc278b15a64fb77c5575b074e1a47/languages/R/linear_algebra/linear_algebra_bench.r">35de11e</a></p>
<p><strong>Testing</strong></p>
<p>It's no good having fast builds of R if they give the wrong results! To make sure that everything is OK, I ran R's installation test suite and everything passed. If you have an account on iceberg, you can see the output from the test suite at <code>/usr/local/packages6/apps/intel/15/R/sequential-3.3.1/install_logs/make_install_tests-R-3.3.1.log</code>.</p>
<p>It's important to note that although the tests passed, there <strong>are</strong> differences in output between this build and the reference build that R's test suite is based on. This is due to a number of factors such as the fact that <a href="http://www.walkingrandomly.com/?p=5380">Floating point addition is not associative</a> and that the signs of eigenvectors are arbitrary and so on.</p>
<p>A discussion around these differences and how they relate to R can be found <a href="http://r.789695.n4.nabble.com/quot-make-check-quot-fails-on-lapack-R-and-stats-Ex-R-td4698672.html">on nabble</a>.</p>
<p><strong>How fast is it?</strong></p>
<p>So is it worth it? I ran a benchmark called <a href="https://github.com/mikecroucher/HPC_Examples/blob/35de11e7c47bc278b15a64fb77c5575b074e1a47/languages/R/linear_algebra/linear_algebra_bench.r#L19">linear_algebra_bench.r</a> that implemented 5 tests</p>
<ul>
<li>MatMul - Multiplies two random 1000 x 5000 matrices together</li>
<li>Chol - Cholesky decomposition of a 5000 x 5000 random matrix</li>
<li>SVD - Singular Value Decompisition of a 10000 x 2000 random matrix</li>
<li>PCA - Principle component analysis of a 10000 x 2000 random matrix</li>
<li>LDA - A Linear Discriminant Analysis problem</li>
</ul>
<p>Run time of these operations compared to Iceberg's standard install of R is shown in the table below.</p>
<ul>
<li>Iceberg submission scripts for these can be found in the <a href="https://github.com/mikecroucher/HPC_Examples">HPC Examples repo</a>
</li>
</ul>
<p><strong>Execution time in seconds (Mean of 5 independent runs) </strong></p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-yw4l{vertical-align:top}
</style>
<table class="tg">
<tr>
<th class="tg-yw4l"></th>
    <th class="tg-yw4l">MatMul</th>
    <th class="tg-yw4l">Chol</th>
    <th class="tg-yw4l">SVD</th>
    <th class="tg-yw4l">PCA</th>
    <th class="tg-yw4l">LDA</th>
  </tr>
<tr>
<td class="tg-yw4l">Standard R</td>
    <td class="tg-yw4l">134.70</td>
    <td class="tg-yw4l">20.95</td>
    <td class="tg-yw4l">46.56</td>
    <td class="tg-yw4l">179.60</td>
    <td class="tg-yw4l">132.40</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with sequential MKL</td>
    <td class="tg-yw4l">12.19</td>
    <td class="tg-yw4l">2.24</td>
    <td class="tg-yw4l">9.13</td>
    <td class="tg-yw4l">24.58</td>
    <td class="tg-yw4l">31.32</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (2 cores)</td>
    <td class="tg-yw4l">7.21</td>
    <td class="tg-yw4l">1.60</td>
    <td class="tg-yw4l">5.43</td>
    <td class="tg-yw4l">14.66</td>
    <td class="tg-yw4l">23.54</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (4 cores)</td>
    <td class="tg-yw4l">3.24</td>
    <td class="tg-yw4l">1.17</td>
    <td class="tg-yw4l">3.34</td>
    <td class="tg-yw4l">7.87</td>
    <td class="tg-yw4l">20.63</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (8 cores)</td>
    <td class="tg-yw4l">1.71</td>
    <td class="tg-yw4l">0.38</td>
    <td class="tg-yw4l">1.99</td>
    <td class="tg-yw4l">5.33</td>
    <td class="tg-yw4l">15.82</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (16 cores)</td>
    <td class="tg-yw4l">0.96</td>
    <td class="tg-yw4l">0.28</td>
    <td class="tg-yw4l">1.60</td>
    <td class="tg-yw4l">4.05</td>
    <td class="tg-yw4l">13.65</td>
  </tr>
</table>
<p><img alt="" src="../images/matmul_r_intel.png"></p>
<p>Another way of viewing these results is to see the speed up compared to the standard install of R. <strong>Even on a single CPU core, the Intel builds are between 4 and 11 times faster than the standard builds</strong>.  Making use of 16 cores takes this up to <strong>141 times faster in the case of Matrix-Matrix Multiplication</strong>!</p>
<p><strong>Speed up compared to standard R</strong></p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-yw4l{vertical-align:top}
</style>
<table class="tg">
<tr>
<th class="tg-yw4l"> </th>
    <th class="tg-yw4l">MatMul</th>
    <th class="tg-yw4l">Chol</th>
    <th class="tg-yw4l">SVD</th>
    <th class="tg-yw4l">PCA</th>
    <th class="tg-yw4l">LDA</th>
  </tr>
<tr>
<td class="tg-yw4l">Standard R</td>
    <td class="tg-yw4l">1</td>
    <td class="tg-yw4l">1</td>
    <td class="tg-yw4l">1</td>
    <td class="tg-yw4l">1</td>
    <td class="tg-yw4l">1</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with sequential MKL</td>
    <td class="tg-yw4l">11</td>
    <td class="tg-yw4l">9</td>
    <td class="tg-yw4l">5</td>
    <td class="tg-yw4l">7</td>
    <td class="tg-yw4l">4</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (2 cores)</td>
    <td class="tg-yw4l">19</td>
    <td class="tg-yw4l">13</td>
    <td class="tg-yw4l">9</td>
    <td class="tg-yw4l">12</td>
    <td class="tg-yw4l">6</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (4 cores)</td>
    <td class="tg-yw4l">42</td>
    <td class="tg-yw4l">18</td>
    <td class="tg-yw4l">14</td>
    <td class="tg-yw4l">23</td>
    <td class="tg-yw4l">6</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (8 cores)</td>
    <td class="tg-yw4l">79</td>
    <td class="tg-yw4l">55</td>
    <td class="tg-yw4l">23</td>
    <td class="tg-yw4l">34</td>
    <td class="tg-yw4l">8</td>
  </tr>
<tr>
<td class="tg-yw4l">Intel R with parallel MKL (16 cores)</td>
    <td class="tg-yw4l">141</td>
    <td class="tg-yw4l">75</td>
    <td class="tg-yw4l">29</td>
    <td class="tg-yw4l">44</td>
    <td class="tg-yw4l">10</td>
  </tr>
</table>
<p><strong>Parallel environment</strong></p>
<p>The type of parallelisation in use here is <a href="http://openmp.org/wp/">OpenMP</a>. As such, you need to use Iceberg's openmp environment.  That is, if you want 8 cores (say), add the following to your submission  script</p>
<pre>
#$ -pe openmp 8
export OMP_NUM_THREADS=8
</pre>

<p>Using OpenMP limits the number of cores you can use per job to the number available on a single node. At the time of writing, this is 16.</p>
<p><strong>How many cores: Finding the sweet spot</strong></p>
<p>Note that everything is fastest when using 16 cores! As such, it may be tempting to always use 16 cores for your jobs. This will almost always be a mistake.
It may be that the aspect of your code that's accelerated by this build doesn't account for much of the runtime of your problem. As such, those 16 cores will sit idle most of the time -- wasting resources.  </p>
<p>You'll also spend a lot longer waiting in the queue for 16 cores than you will for 2 cores which may swap any speed gains.</p>
<p>You should always perform scaling experiments before deciding how many cores to use for your jobs. Consider the Linear Discriminant Analysis problem, for example. Using just one core, Intel build gives us a 4 times speed-up compared to the standard build. Moving to 8 cores only makes it twice as fast again. As such, if you had lots of these jobs to do, your throughput would be higher running lots of single core jobs compared to lots of 8 core jobs.</p>
<p>If matrix-matrix multiply dominates your runtime, on the other hand, it may well be worth using 16 cores.</p>
<p><strong>Using this version of R for your own work</strong></p>
<p>As a user, there are a few things you need to be aware of with the Intel builds of R so I've created a separate documentation page for them.  This is currently at
<a href="http://docs.hpc.shef.ac.uk/en/latest/iceberg/software/apps/intel_r.html">http://docs.hpc.shef.ac.uk/en/latest/iceberg/software/apps/intel_r.html</a></p>
<p>My recommendation for using these builds is to work through the following procedure</p>
<ul>
<li>Ensure that your code runs with Iceberg's standard version of R and produce a test result.</li>
<li>In the first instance, switch to the sequential version of the Intel R build. In the best case, this will just require changing the module. You may also need to install some of your packages since the Intel build has a separate packages directory to the standard build.</li>
<li>If you see speed-up <strong>and</strong> the results are consistent with your test result, try the parallel version. Initially start with 2 cores and move upwards to find the sweet spot.</li>
</ul>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="the-university-of-sheffield-named-an-nvidia-gpu-education-center/" class="u-url">The University of Sheffield named an NVIDIA GPU Education Center</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/paul-richmond/">Paul Richmond</a>
            </span></p>
            <p class="dateline"><a href="the-university-of-sheffield-named-an-nvidia-gpu-education-center/" rel="bookmark"><time class="published dt-published" datetime="2016-07-02T17:50:04+01:00" title="2016-07-02 17:50">2016-07-02 17:50</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p><img src="../images/NVIDIA_education.jpg" alt="Sheffield NVIDIA Education Centre" align="right" width="20%"></p>
<p>This week I am very pleased to announce that the University of Sheffield has been awarded the status of an NVIDIA CUDA Education Centre.</p>
<p>The faculty of Engineering has featured this in its latest <a href="http://www.sheffield.ac.uk/faculty/engineering/news/nvidia-1.587003">faculty newsletter</a> and the Department of Computer Science has published more details in a <a href="http://www.sheffield.ac.uk/dcs/latest-news/nvidia-1.587214">news feature</a>.</p>
<h3>But what does this mean to the RSE community at Sheffield and beyond?</h3>
<p>The recognition of being an NVIDIA education centre is a reflection of the teaching that is provided by The University of Sheffield on the subject of GPU computing. In case you are unaware of what teaching there is, I have a 4th year and Masters teaching module <a href="http://paulrichmond.shef.ac.uk/teaching/COM4521/">COM4521/COM6521</a> which ran for the first time in the 2015/2016 Spring Semester. This course will be run annually and is open to research staff as well as taught students. Last time there was roughly a 50:50 mix including senior research staff and PhD students. It is much more involved that the one or two day courses which typically give only an introduction to GPU programming. If you are a researcher looking to exploit GPU performance in your research then this course is an opportunity to learn some new skills.</p>
<p>In the future this course will be made freely available so even researchers outside of The University of Sheffield will be able to go through the notes and worked examples (lab sheets). </p>
<p>Some of the other benefits of being an NVIDIA Eduction (and also an NVIDIA Research) centre are;</p>
<ul>
<li>Access to NVIDIA GPU hardware and software (via Iceberg and in the Diamond labs) </li>
<li>Significant discount on Tesla hardware purchases</li>
<li>Access to NVIDIA parallel programming experts and resources</li>
<li>Access to educational webinars and an array of teaching materials</li>
<li>Free in the cloud GPU programming training at <a href="https://nvidia.qwiklab.com/">nvidia.qwiklab.com</a>
</li>
<li>Support in the form of letters of support (with contributions in kind) for research proposals with emphasis on GPU computing or deep learning</li>
<li>Joint promotion, public relations, and press activities with NVIDIA</li>
</ul>
<h3>Other Training Opportunities</h3>
<p>Through <a href="http://rse.shef.ac.uk/">RSE Sheffield</a> and <a href="http://gpucomputing.sites.sheffield.ac.uk">GPUComputing@Sheffield</a> shorter courses for GPU computing are also available. I will be announcing dates for 1-2 day CUDA courses shortly and am working with CICS in developing new Python CUDA material. </p>
<p>For those that missed the sign-up, we are also running a two day deep learning with GPUs course in July. The places for this were in high demand and filled up within a day. This course will be repeated in due time and material from the course will be made available off-line.</p>
<p>Other GPU announcements will be made on both this RSE blog and on the <a href="https://groups.google.com/a/sheffield.ac.uk/forum/#!forum/gpucomputing">GPUComputing@Sheffield mailing list</a>. Expect some exciting new hardware and software once the Iceberg upgrade is complete (shortly).</p>
<p>Paul</p>
</div>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="." rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2017         <a href="mailto:rse@sheffield.ac.uk">Mike Croucher and Paul Richmond</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
